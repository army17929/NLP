{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas 모듈에서는 dataframe을 선언하는 것이 매우 중요하다. 올바른 형태를 가진 dataframe을 가진 상태에서만 그 이후의 행동이 가능해진다. \n",
    "코딩을 하다보면, pandas에서 서로 다른 두 dataframe을 합쳐야 하는 경우를 매우 흔하게 볼 수 있다.\n",
    "이 때 사용할 수 있는 command가 총 세 가지가 있다. \n",
    "1) concatenate - 두 개의 dataframe을 위아래로 이어붙인다고 생각하면 된다. \n",
    "2) join - join 은 두 개의 df를 양 옆으로 이어붙인다. \n",
    "3) merge - merge() 함수는 서로 다른 두 데이터프레임을 각 데이터에 존재하는 고유값을 기준으로 병합할 때 사용한다. \n",
    "pd.merge(df_left,df_right,how='inner', on = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id1': [1, 2, 3, 4, 5], 'name': ['a', 'b', 'c', 'd', 'e'], 'price': [10, 20, 30, 40, 50]}\n",
      "{'id2': [1, 2, 3, 4], 'name': ['a', 'b', 'z', 'z'], 'price': [10, 20, 100, 100]}\n",
      "   id1 namel_  pricel_  id2 namer_  pricer_\n",
      "0    1      a       10  1.0      a     10.0\n",
      "1    2      b       20  2.0      b     20.0\n",
      "2    3      c       30  3.0      z    100.0\n",
      "3    4      d       40  4.0      z    100.0\n",
      "4    5      e       50  NaN    NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# This is a notebook for the coding implementation.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "dict_a = {\n",
    "    'id1': [1, 2, 3, 4, 5],\n",
    "    'name': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'price': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "dict_b = {\n",
    "    'id2': [1, 2, 3, 4],\n",
    "    'name': ['a', 'b', 'z', 'z'],\n",
    "    'price': [10, 20, 100, 100]\n",
    "}\n",
    "\n",
    "df_a = pd.DataFrame(dict_a)\n",
    "df_b = pd.DataFrame(dict_b)\n",
    "\n",
    "print(dict_a)\n",
    "print(dict_b)\n",
    "\n",
    "df_test = df_a.join(df_b,lsuffix ='l_',rsuffix ='r_')\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  4  9\n",
      "1  1  4\n",
      "2  5  6\n",
      "   A  B\n",
      "0  5  9\n",
      "1  2  4\n",
      "2  6  6\n",
      "   A   B\n",
      "0  5  10\n",
      "1  2   5\n",
      "2  6   7\n"
     ]
    }
   ],
   "source": [
    "# This cell is about pandas.apply and lambda. \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[4,9],[1,4],[5,6]],columns = ['A','B'])\n",
    "print(df)\n",
    "\n",
    "# Let's say we want to apply certain function on the column A. \n",
    "def plus_one(x):\n",
    "    x += 1\n",
    "    return x\n",
    "\n",
    "df['A'] = df['A'].apply(plus_one)\n",
    "print(df)\n",
    "\n",
    "# Motivation - how do we simplify this process?\n",
    "# Initialize the dataframe\n",
    "df = pd.DataFrame([[4,9],[1,4],[5,6]],columns = ['A','B'])\n",
    "df = df.apply(lambda a : a+1 )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pconda\n"
     ]
    }
   ],
   "source": [
    "# This cell is about string.maketrans()\n",
    "import string\n",
    "\n",
    "obj = 'python'\n",
    "before = 'ython'\n",
    "after = 'conda'\n",
    "sen = obj.maketrans(before,after)\n",
    "print(obj.translate(sen)) # This function is substituting the string with another string.\n",
    "# The prerequisite for this function is the before and after should have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like apple and apple\n"
     ]
    }
   ],
   "source": [
    "# This cell is about re.sub() function. \n",
    "# Example of this function is as follows. \n",
    "import re \n",
    "\n",
    "text = 'I like abple and abple'\n",
    "text_mod = re.sub('abple','apple',text)\n",
    "\n",
    "print(text_mod) # So this function is replacing certain words with another words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publish or Periiish\n"
     ]
    }
   ],
   "source": [
    "# This cell is about removing the repeated characters.\n",
    "import re # Regular expression \n",
    "text = 'Publish or Periiish'\n",
    "text_sub = re.sub(r'(.)1+',r'1',text) # +1 means that if the string is repeated more than 1 time, it is removed. \n",
    "#text_sub = re.sub(r'(.)1+',r'1',text)\n",
    "print(text_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cosmosproject.tistory.com/180\n",
    "The site above explains about the syntax of the re.sub() function.\n",
    "https://www.nextree.co.kr/p4327/\n",
    "This site contains nice reference for regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Publish', 'or', 'Perish']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# Regular expression is very useful for text processing.\n",
    "# But, it will take some time to be familiar with re.\n",
    "text = 'Publish or Perish!'\n",
    "#tokenizer = RegexpTokenizer(r\"w+\", gaps = True)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# For the second argument, we can specify the criteria for the tokenization.\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'greatest', 'glori', 'in', 'live', 'lie', 'not', 'in', 'never', 'fall', 'but', 'in', 'rise', 'everi', 'time', 'we', 'fall']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\every\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'greatest', 'glory', 'in', 'living', 'lie', 'not', 'in', 'never', 'falling', 'but', 'in', 'rising', 'every', 'time', 'we', 'fall']\n"
     ]
    }
   ],
   "source": [
    "# In this cell, I tried to observe the difference between stemming and lemmatizing.\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "dir = r'C:\\Program Files (x86)\\WordNet\\2.1'\n",
    "os.chdir(dir)\n",
    "\n",
    "stemmizer = nltk.PorterStemmer()\n",
    "text = 'The greatest glory in living lies not in never falling, but in rising every time we fall.'\n",
    "text = tokenizer.tokenize(text)\n",
    "\n",
    "text_stem = [stemmizer.stem(word) for word in text]\n",
    "# In order to use for loop, we need to put those in the list.\n",
    "print((text_stem))\n",
    "# The result is not 100% accurate.\n",
    "# How about lemmatizer?\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "text_lem = [lemmatizer.lemmatize(word) for word in text]\n",
    "print(text_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89d36f605ae3aa71791baed15afeef29ec51f91c7f29be8219898f2e245b2a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
